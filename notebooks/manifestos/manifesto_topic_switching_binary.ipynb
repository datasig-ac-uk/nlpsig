{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a983a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import nlpsig\n",
    "from nlpsig.deepsignet import StackedDeepSigNet\n",
    "from nlpsig.focal_loss import FocalLoss, ClassBalanced_FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8808a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_data(data_folder_path):\n",
    "    print(f\"looking in {data_folder_path} directory...\")\n",
    "    manifesto_dfs = []\n",
    "    for filename in os.listdir(data_folder_path):\n",
    "        print(f\"- reading {filename}...\")\n",
    "        # parse filename for metadata\n",
    "        filename_split = filename.split(\"_\")\n",
    "        party_id = int(filename_split[0])\n",
    "        year = int(filename_split[1][0:4])\n",
    "        month = int(filename_split[1][4:6])\n",
    "        doc_id = f\"{party_id}_{year}\"\n",
    "        # read dataframe and add metadata\n",
    "        df = pd.read_csv(f\"data/{filename}\")[[\"text\", \"cmp_code\"]]\n",
    "        df = df[df[\"cmp_code\"]!=\"H\"].dropna().reset_index(drop=True)\n",
    "        df[\"topic\"] = [int(str(code)[0]) for code in df[\"cmp_code\"]]\n",
    "        df[\"switched_topic\"] = [1] + [int(df[\"topic\"].iloc[i]!=df[\"topic\"].iloc[i-1])\n",
    "                                      for i in range(1, len(df))]\n",
    "        df[\"party_id\"] = party_id\n",
    "        df[\"doc_id\"] = f\"{party_id}_{year}\"\n",
    "        df[\"datetime\"] = pd.Timestamp(f\"{year}-{month}\")\n",
    "        manifesto_dfs.append(df)\n",
    "    return pd.concat(manifesto_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df78810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking in data/ directory...\n",
      "- reading 51902_201706.csv...\n",
      "- reading 51902_201505.csv...\n",
      "- reading 51320_201912.csv...\n",
      "- reading 51620_201706.csv...\n",
      "- reading 51620_201505.csv...\n",
      "- reading 51421_201706.csv...\n",
      "- reading 51421_201505.csv...\n",
      "- reading 51421_201912.csv...\n",
      "- reading 51902_201912.csv...\n",
      "- reading 51320_201706.csv...\n",
      "- reading 51620_201912.csv...\n",
      "- reading 51320_201505.csv...\n"
     ]
    }
   ],
   "source": [
    "manifesto_df = concatenate_data(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00bb922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cmp_code</th>\n",
       "      <th>topic</th>\n",
       "      <th>switched_topic</th>\n",
       "      <th>party_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNP MPs have used their influence to deliver p...</td>\n",
       "      <td>305.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Here’s just some of what a strong team of SNP ...</td>\n",
       "      <td>305.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When the Scotland Bill was going through Westm...</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And it was SNP MPs, working with the Scottish ...</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The SNP secured a deal that ensures Scotland w...</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SNP MPs have consistently opposed Tory austerity.</td>\n",
       "      <td>504</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Our MPs have been instrumental in forcing UK g...</td>\n",
       "      <td>504</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alison Thewliss has been at the forefront of t...</td>\n",
       "      <td>504</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and force women to prove they have been raped ...</td>\n",
       "      <td>503</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SNP MPs have worked with Women Against State P...</td>\n",
       "      <td>503</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text cmp_code  topic  \\\n",
       "0  SNP MPs have used their influence to deliver p...    305.1      3   \n",
       "1  Here’s just some of what a strong team of SNP ...    305.1      3   \n",
       "2  When the Scotland Bill was going through Westm...      301      3   \n",
       "3  And it was SNP MPs, working with the Scottish ...      301      3   \n",
       "4  The SNP secured a deal that ensures Scotland w...      301      3   \n",
       "5  SNP MPs have consistently opposed Tory austerity.      504      5   \n",
       "6  Our MPs have been instrumental in forcing UK g...      504      5   \n",
       "7  Alison Thewliss has been at the forefront of t...      504      5   \n",
       "8  and force women to prove they have been raped ...      503      5   \n",
       "9  SNP MPs have worked with Women Against State P...      503      5   \n",
       "\n",
       "   switched_topic  party_id      doc_id   datetime  \n",
       "0               1     51902  51902_2017 2017-06-01  \n",
       "1               0     51902  51902_2017 2017-06-01  \n",
       "2               0     51902  51902_2017 2017-06-01  \n",
       "3               0     51902  51902_2017 2017-06-01  \n",
       "4               0     51902  51902_2017 2017-06-01  \n",
       "5               1     51902  51902_2017 2017-06-01  \n",
       "6               0     51902  51902_2017 2017-06-01  \n",
       "7               0     51902  51902_2017 2017-06-01  \n",
       "8               0     51902  51902_2017 2017-06-01  \n",
       "9               0     51902  51902_2017 2017-06-01  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44217a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10746\n",
       "1     4864\n",
       "Name: switched_topic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_df[\"switched_topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a5a319f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    5300\n",
       "4    3872\n",
       "6    1547\n",
       "1    1504\n",
       "2    1235\n",
       "3    1101\n",
       "7    1024\n",
       "0      27\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_df[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c017ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51421    4515\n",
       "51620    4307\n",
       "51320    4039\n",
       "51902    2749\n",
       "Name: party_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_df[\"party_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507f8a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51421_2015    1917\n",
       "51320_2019    1702\n",
       "51620_2015    1588\n",
       "51620_2017    1496\n",
       "51421_2019    1467\n",
       "51320_2017    1328\n",
       "51620_2019    1223\n",
       "51421_2017    1131\n",
       "51902_2019    1071\n",
       "51320_2015    1009\n",
       "51902_2015     892\n",
       "51902_2017     786\n",
       "Name: doc_id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_df[\"doc_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc0510",
   "metadata": {},
   "source": [
    "## Model specifics\n",
    "\n",
    "Nested dictionary for models specifications.\n",
    "\n",
    "This includes models for encoding text, path signature and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7cf22c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_specifics = {\n",
    "    \"encoder_args\": {\n",
    "        \"feature_name\": \"text\", # column corresponding to the sentences\n",
    "        \"model_name\": \"all-mpnet-base-v2\", #options: all-mpnet-base-v2, all-distilroberta-v1, all-MiniLM-L12-v2\n",
    "        \"model_encoder_args\": {\n",
    "            \"batch_size\": 64,\n",
    "            \"show_progress_bar\": True,\n",
    "            \"output_value\": 'sentence_embedding', \n",
    "            \"convert_to_numpy\": True,\n",
    "            \"convert_to_tensor\": False,\n",
    "            \"device\": None,\n",
    "            \"normalize_embeddings\": False\n",
    "        }\n",
    "    },\n",
    "    \"dim_reduction\": {\n",
    "        \"method\": 'umap', #options: ppapca, ppapcappa, umap\n",
    "        \"n_components\": 50, # options: any int number between 1 and embedding dimensions\n",
    "    },\n",
    "    \"embedding\":{\n",
    "        \"global_embedding_tp\": 'SBERT', #options: SBERT, BERT_cls , BERT_mean, BERT_max\n",
    "        \"post_embedding_tp\": 'sentence', #options: sentence, reduced\n",
    "        \"feature_combination_method\": 'attention', #options concatenation, attention \n",
    "    },\n",
    "    \"time_injection\": {\n",
    "        \"history_tp\": 'timestamp', #options: timestamp, None\n",
    "        \"post_tp\": 'timestamp', #options: timestamp, timediff, None\n",
    "    },\n",
    "    \"signature\": {\n",
    "        \"dimensions\": 3, #options: any int number larger than 1\n",
    "        \"method\": 'log', # options: log, sig\n",
    "        \"interval\": 1/12\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a35e43",
   "metadata": {},
   "source": [
    "## Obtaining SBERT Embeddings\n",
    "\n",
    "We can use the `SentenceEncoder` class within `nlpsig` to obtain sentence embeddings from a model. Here, we have defined the encoder arguments in `model_specifics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "470b0bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'feature_name': 'text',\n",
       " 'model_name': 'all-mpnet-base-v2',\n",
       " 'model_encoder_args': {'batch_size': 64,\n",
       "  'show_progress_bar': True,\n",
       "  'output_value': 'sentence_embedding',\n",
       "  'convert_to_numpy': True,\n",
       "  'convert_to_tensor': False,\n",
       "  'device': None,\n",
       "  'normalize_embeddings': False}}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_specifics[\"encoder_args\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d28b22",
   "metadata": {},
   "source": [
    "We can pass these into the constructor of the class to initialise our text encoder as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ffa9205f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'all-mpnet-base-v2'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_specifics[\"encoder_args\"][\"model_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "07fe57d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the Text Encoder \n",
    "text_encoder = nlpsig.SentenceEncoder(df=manifesto_df,\n",
    "                                      **model_specifics[\"encoder_args\"])\n",
    "# load pretrained model (model_specifics[\"encoder_args\"][\"model_name\"])\n",
    "text_encoder.load_pretrained_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b0890",
   "metadata": {},
   "source": [
    "The class has a `.encode_sentence_transformer()` method which first loads in the model (using the `model_name` and `model_args` attributes) and then obtains an embedding for each sentence. These sentence embeddings are then stored in the `embeddings_sentence` attribute of the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1b984327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] number of sentences to encode: 15610\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dec86d12014c8fafb79eea4a4f8b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_encoder.obtain_embeddings()\n",
    "embeddings_sentence = text_encoder.sentence_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785985df",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction with UMAP\n",
    "\n",
    "Here we specified our choices in `model_specifics` above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be889a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': 'umap', 'n_components': 50}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_specifics[\"dim_reduction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "efd2a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = nlpsig.DimReduce(**model_specifics[\"dim_reduction\"])\n",
    "embeddings_reduced = reduction.fit_transform(embeddings_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "14fff4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15610, 768)\n",
      "(15610, 50)\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_sentence.shape)\n",
    "print(embeddings_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a38be",
   "metadata": {},
   "source": [
    "## Data preparation: Time injection and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27b775b6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Concatenating the embeddings to the dataframe...\n",
      "[INFO] - columns beginning with 'e' denote the full embddings.\n",
      "[INFO] - columns beginning with 'd' denote the dimension reduced embeddings.\n",
      "[INFO] Adding time feature columns into dataframe in `.df`.\n",
      "[INFO] Adding 'time_encoding' and feature...\n",
      "[INFO] Adding 'time_diff' and feature...\n",
      "[INFO] Adding 'timeline_index' feature...\n"
     ]
    }
   ],
   "source": [
    "manifesto_data = nlpsig.PrepareData(manifesto_df,\n",
    "                                    id_column=\"doc_id\",\n",
    "                                    labels_column=\"switched_topic\",\n",
    "                                    embeddings=embeddings_sentence,\n",
    "                                    embeddings_reduced=embeddings_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "972ca765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51421_2015    1917\n",
       "51320_2019    1702\n",
       "51620_2015    1588\n",
       "51620_2017    1496\n",
       "51421_2019    1467\n",
       "51320_2017    1328\n",
       "51620_2019    1223\n",
       "51421_2017    1131\n",
       "51902_2019    1071\n",
       "51320_2015    1009\n",
       "51902_2015     892\n",
       "51902_2017     786\n",
       "Name: doc_id, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_data.df[\"doc_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41f2cc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cmp_code</th>\n",
       "      <th>topic</th>\n",
       "      <th>switched_topic</th>\n",
       "      <th>party_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>...</th>\n",
       "      <th>e762</th>\n",
       "      <th>e763</th>\n",
       "      <th>e764</th>\n",
       "      <th>e765</th>\n",
       "      <th>e766</th>\n",
       "      <th>e767</th>\n",
       "      <th>e768</th>\n",
       "      <th>time_encoding</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>timeline_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13753</th>\n",
       "      <td>SNP MPs have used their influence to deliver p...</td>\n",
       "      <td>305.1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>6.218624</td>\n",
       "      <td>5.405863</td>\n",
       "      <td>7.141194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015981</td>\n",
       "      <td>-0.014767</td>\n",
       "      <td>0.026448</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>-0.017059</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.015159</td>\n",
       "      <td>2017.413699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13754</th>\n",
       "      <td>Here’s just some of what a strong team of SNP ...</td>\n",
       "      <td>305.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>6.121441</td>\n",
       "      <td>5.327885</td>\n",
       "      <td>7.136108</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012643</td>\n",
       "      <td>-0.033004</td>\n",
       "      <td>0.015802</td>\n",
       "      <td>-0.003156</td>\n",
       "      <td>-0.017330</td>\n",
       "      <td>0.027937</td>\n",
       "      <td>0.013548</td>\n",
       "      <td>2017.413699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13755</th>\n",
       "      <td>When the Scotland Bill was going through Westm...</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>6.353848</td>\n",
       "      <td>5.650436</td>\n",
       "      <td>7.309916</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022350</td>\n",
       "      <td>-0.015041</td>\n",
       "      <td>-0.038259</td>\n",
       "      <td>-0.000943</td>\n",
       "      <td>-0.023851</td>\n",
       "      <td>-0.018221</td>\n",
       "      <td>0.020819</td>\n",
       "      <td>2017.413699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13756</th>\n",
       "      <td>And it was SNP MPs, working with the Scottish ...</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>6.474751</td>\n",
       "      <td>5.557942</td>\n",
       "      <td>7.597468</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>-0.022373</td>\n",
       "      <td>0.014007</td>\n",
       "      <td>-0.006234</td>\n",
       "      <td>0.015914</td>\n",
       "      <td>0.018991</td>\n",
       "      <td>2017.413699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13757</th>\n",
       "      <td>The SNP secured a deal that ensures Scotland w...</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>6.893159</td>\n",
       "      <td>5.808902</td>\n",
       "      <td>7.574815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031720</td>\n",
       "      <td>-0.014070</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.028775</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.018755</td>\n",
       "      <td>-0.021968</td>\n",
       "      <td>2017.413699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14534</th>\n",
       "      <td>The disgraceful condition of the housing provi...</td>\n",
       "      <td>201.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>5.152985</td>\n",
       "      <td>4.770663</td>\n",
       "      <td>6.742881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011745</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>-0.005464</td>\n",
       "      <td>0.014512</td>\n",
       "      <td>-0.022729</td>\n",
       "      <td>-0.041512</td>\n",
       "      <td>0.049706</td>\n",
       "      <td>2017.413699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14535</th>\n",
       "      <td>The Scottish Government’s work to resettle Syr...</td>\n",
       "      <td>201.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>4.823460</td>\n",
       "      <td>5.087404</td>\n",
       "      <td>6.052791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033104</td>\n",
       "      <td>-0.021670</td>\n",
       "      <td>-0.040489</td>\n",
       "      <td>0.022394</td>\n",
       "      <td>-0.003573</td>\n",
       "      <td>0.060122</td>\n",
       "      <td>0.058902</td>\n",
       "      <td>2017.413699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14536</th>\n",
       "      <td>We will urge the UK government to work with th...</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>4.777165</td>\n",
       "      <td>4.842837</td>\n",
       "      <td>6.092124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029256</td>\n",
       "      <td>-0.005607</td>\n",
       "      <td>-0.014617</td>\n",
       "      <td>0.028316</td>\n",
       "      <td>-0.026071</td>\n",
       "      <td>-0.015531</td>\n",
       "      <td>0.037127</td>\n",
       "      <td>2017.413699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14537</th>\n",
       "      <td>rather than use private contractors who have p...</td>\n",
       "      <td>413</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>5.953185</td>\n",
       "      <td>4.654902</td>\n",
       "      <td>6.219607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021102</td>\n",
       "      <td>0.066897</td>\n",
       "      <td>-0.031050</td>\n",
       "      <td>-0.022594</td>\n",
       "      <td>-0.004096</td>\n",
       "      <td>-0.021181</td>\n",
       "      <td>0.018906</td>\n",
       "      <td>2017.413699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14538</th>\n",
       "      <td>There needs to be reform to the detention and ...</td>\n",
       "      <td>201.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>51902</td>\n",
       "      <td>51902_2017</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>4.063104</td>\n",
       "      <td>4.427969</td>\n",
       "      <td>5.432862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001870</td>\n",
       "      <td>-0.001497</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>0.029493</td>\n",
       "      <td>0.018048</td>\n",
       "      <td>0.059375</td>\n",
       "      <td>0.038039</td>\n",
       "      <td>2017.413699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>786 rows × 828 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text cmp_code  topic  \\\n",
       "13753  SNP MPs have used their influence to deliver p...    305.1      3   \n",
       "13754  Here’s just some of what a strong team of SNP ...    305.1      3   \n",
       "13755  When the Scotland Bill was going through Westm...      301      3   \n",
       "13756  And it was SNP MPs, working with the Scottish ...      301      3   \n",
       "13757  The SNP secured a deal that ensures Scotland w...      301      3   \n",
       "...                                                  ...      ...    ...   \n",
       "14534  The disgraceful condition of the housing provi...    201.2      2   \n",
       "14535  The Scottish Government’s work to resettle Syr...    201.2      2   \n",
       "14536  We will urge the UK government to work with th...      301      3   \n",
       "14537  rather than use private contractors who have p...      413      4   \n",
       "14538  There needs to be reform to the detention and ...    201.2      2   \n",
       "\n",
       "       switched_topic  party_id      doc_id   datetime        d1        d2  \\\n",
       "13753               1     51902  51902_2017 2017-06-01  6.218624  5.405863   \n",
       "13754               0     51902  51902_2017 2017-06-01  6.121441  5.327885   \n",
       "13755               0     51902  51902_2017 2017-06-01  6.353848  5.650436   \n",
       "13756               0     51902  51902_2017 2017-06-01  6.474751  5.557942   \n",
       "13757               0     51902  51902_2017 2017-06-01  6.893159  5.808902   \n",
       "...               ...       ...         ...        ...       ...       ...   \n",
       "14534               0     51902  51902_2017 2017-06-01  5.152985  4.770663   \n",
       "14535               0     51902  51902_2017 2017-06-01  4.823460  5.087404   \n",
       "14536               1     51902  51902_2017 2017-06-01  4.777165  4.842837   \n",
       "14537               1     51902  51902_2017 2017-06-01  5.953185  4.654902   \n",
       "14538               1     51902  51902_2017 2017-06-01  4.063104  4.427969   \n",
       "\n",
       "             d3  ...      e762      e763      e764      e765      e766  \\\n",
       "13753  7.141194  ...  0.015981 -0.014767  0.026448  0.002084 -0.017059   \n",
       "13754  7.136108  ... -0.012643 -0.033004  0.015802 -0.003156 -0.017330   \n",
       "13755  7.309916  ... -0.022350 -0.015041 -0.038259 -0.000943 -0.023851   \n",
       "13756  7.597468  ...  0.029210  0.002856 -0.022373  0.014007 -0.006234   \n",
       "13757  7.574815  ...  0.031720 -0.014070  0.001398  0.028775  0.021897   \n",
       "...         ...  ...       ...       ...       ...       ...       ...   \n",
       "14534  6.742881  ... -0.011745  0.008737 -0.005464  0.014512 -0.022729   \n",
       "14535  6.052791  ...  0.033104 -0.021670 -0.040489  0.022394 -0.003573   \n",
       "14536  6.092124  ...  0.029256 -0.005607 -0.014617  0.028316 -0.026071   \n",
       "14537  6.219607  ...  0.021102  0.066897 -0.031050 -0.022594 -0.004096   \n",
       "14538  5.432862  ...  0.001870 -0.001497 -0.000473  0.029493  0.018048   \n",
       "\n",
       "           e767      e768  time_encoding  time_diff  timeline_index  \n",
       "13753  0.001952  0.015159    2017.413699        0.0               0  \n",
       "13754  0.027937  0.013548    2017.413699        0.0               1  \n",
       "13755 -0.018221  0.020819    2017.413699        0.0               2  \n",
       "13756  0.015914  0.018991    2017.413699        0.0               3  \n",
       "13757  0.018755 -0.021968    2017.413699        0.0               4  \n",
       "...         ...       ...            ...        ...             ...  \n",
       "14534 -0.041512  0.049706    2017.413699        0.0             781  \n",
       "14535  0.060122  0.058902    2017.413699        0.0             782  \n",
       "14536 -0.015531  0.037127    2017.413699        0.0             783  \n",
       "14537 -0.021181  0.018906    2017.413699        0.0             784  \n",
       "14538  0.059375  0.038039    2017.413699        0.0             785  \n",
       "\n",
       "[786 rows x 828 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_data.df[manifesto_data.df[\"doc_id\"]==\"51902_2017\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163fa9d",
   "metadata": {},
   "source": [
    "## Obtaining path by looking at post history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "812395df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Padding ids and storing in `.df_padded` and `.array_padded` attributes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████| 15610/15610 [00:23<00:00, 653.79it/s]\n"
     ]
    }
   ],
   "source": [
    "time_features = [\"timeline_index\", \"time_encoding\"]\n",
    "history_path = manifesto_data.pad(pad_by=\"history\",\n",
    "                                  method=\"k_last\",\n",
    "                                  zero_padding=True,\n",
    "                                  k=10,\n",
    "                                  time_feature=time_features,\n",
    "                                  standardise_time_feature=False,\n",
    "                                  embeddings=\"dim_reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c50d72c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15610, 10, 54)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_path.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "41a10571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'switched_topic'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_data.label_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cef1508b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2015.3287671232877, 5.585601329803467, 5.373188495635986,\n",
       "        7.216732025146484, 6.7016377449035645, 4.010620594024658,\n",
       "        1.9871352910995483, 4.562832355499268, 7.122035026550293,\n",
       "        4.239704608917236, 3.925722599029541, 5.707393646240234,\n",
       "        6.722735404968262, 3.756204128265381, 3.753582715988159,\n",
       "        0.9717355370521545, 6.577835559844971, 5.097364902496338,\n",
       "        5.210720539093018, 1.648322343826294, 6.5491838455200195,\n",
       "        2.582465171813965, 3.3948566913604736, 3.4996731281280518,\n",
       "        5.060497283935547, 4.592323303222656, 4.1421027183532715,\n",
       "        5.254263401031494, 5.300419807434082, 4.375033855438232,\n",
       "        5.108604431152344, 5.087096691131592, 5.567975997924805,\n",
       "        8.174856185913086, 3.72859787940979, 3.9155287742614746,\n",
       "        4.524398326873779, 5.853325843811035, 3.465318441390991,\n",
       "        5.750558376312256, 7.4231767654418945, 4.017478942871094,\n",
       "        4.7644829750061035, 4.94251012802124, 5.548069953918457,\n",
       "        3.6939914226531982, 4.653692722320557, 4.002806663513184,\n",
       "        7.775050640106201, 5.832951545715332, 6.269733905792236,\n",
       "        '51320_2015', 1],\n",
       "       [1, 2015.3287671232877, 5.577667713165283, 5.488556861877441,\n",
       "        7.423335075378418, 6.544344902038574, 3.915041208267212,\n",
       "        1.7204127311706543, 4.280709743499756, 6.990673542022705,\n",
       "        4.049659729003906, 3.9395809173583984, 5.664320468902588,\n",
       "        6.481485366821289, 3.708584785461426, 3.470181703567505,\n",
       "        0.8092894554138184, 6.638092517852783, 4.917705535888672,\n",
       "        5.100055694580078, 1.6873975992202759, 6.553181171417236,\n",
       "        2.790543556213379, 3.5695793628692627, 3.381916046142578,\n",
       "        5.0749053955078125, 4.422973155975342, 4.191803932189941,\n",
       "        5.381864547729492, 5.1622090339660645, 4.41082763671875,\n",
       "        5.149899005889893, 5.154417991638184, 5.504986763000488,\n",
       "        8.191780090332031, 3.8300187587738037, 3.954209804534912,\n",
       "        4.4650373458862305, 5.8417205810546875, 3.4744160175323486,\n",
       "        5.768961429595947, 7.4322190284729, 3.945551872253418,\n",
       "        4.791947841644287, 4.907891273498535, 5.5329670906066895,\n",
       "        3.6775214672088623, 4.645329475402832, 3.9993975162506104,\n",
       "        7.735293388366699, 5.878067970275879, 6.284836769104004,\n",
       "        '51320_2015', 0],\n",
       "       [2, 2015.3287671232877, 5.492272853851318, 5.2362380027771,\n",
       "        7.067239761352539, 6.707651615142822, 3.810377359390259,\n",
       "        2.013356924057007, 4.995176792144775, 6.89080286026001,\n",
       "        4.323160648345947, 3.655416965484619, 5.539630889892578,\n",
       "        6.506984233856201, 3.8806979656219482, 3.838563919067383,\n",
       "        1.1521165370941162, 6.348346710205078, 4.840224742889404,\n",
       "        5.327639102935791, 1.8102139234542847, 6.5174336433410645,\n",
       "        2.546684980392456, 3.455537796020508, 3.5959420204162598,\n",
       "        4.983174800872803, 4.520676136016846, 4.174410343170166,\n",
       "        5.178873062133789, 5.170277118682861, 4.42915678024292,\n",
       "        5.114082336425781, 5.177459239959717, 5.6799211502075195,\n",
       "        8.239398956298828, 3.652846574783325, 3.991196870803833,\n",
       "        4.536644458770752, 5.810290336608887, 3.5229697227478027,\n",
       "        5.787875652313232, 7.413642406463623, 4.098570346832275,\n",
       "        4.7447028160095215, 4.963815689086914, 5.4944963455200195,\n",
       "        3.6969375610351562, 4.647871971130371, 4.028535842895508,\n",
       "        7.777678966522217, 5.856811046600342, 6.2495832443237305,\n",
       "        '51320_2015', 0],\n",
       "       [3, 2015.3287671232877, 5.453681945800781, 5.575738906860352,\n",
       "        7.4125823974609375, 6.085537910461426, 3.918347120285034,\n",
       "        1.671298623085022, 5.061848163604736, 6.687990665435791,\n",
       "        4.187758445739746, 4.115754127502441, 5.525689125061035,\n",
       "        6.1521897315979, 3.9226949214935303, 4.062742710113525,\n",
       "        1.1006532907485962, 6.0230207443237305, 4.518646240234375,\n",
       "        5.39885950088501, 2.1088674068450928, 6.526498317718506,\n",
       "        2.8058648109436035, 3.635723829269409, 3.7707557678222656,\n",
       "        4.981564044952393, 4.322734355926514, 4.176937103271484,\n",
       "        5.369829177856445, 4.986732006072998, 4.6791300773620605,\n",
       "        5.161693096160889, 5.386397361755371, 5.566462993621826,\n",
       "        8.31689453125, 3.6871604919433594, 4.034115314483643,\n",
       "        4.468372821807861, 5.79555082321167, 3.549795389175415,\n",
       "        5.854804039001465, 7.39223575592041, 4.102655410766602,\n",
       "        4.770327091217041, 5.0801777839660645, 5.4158430099487305,\n",
       "        3.734529972076416, 4.5801849365234375, 4.0466628074646,\n",
       "        7.648481369018555, 5.98142147064209, 6.2180495262146,\n",
       "        '51320_2015', 0],\n",
       "       [0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        '51320_2015', -1],\n",
       "       [0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        '51320_2015', -1],\n",
       "       [0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        '51320_2015', -1],\n",
       "       [0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        '51320_2015', -1],\n",
       "       [0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        '51320_2015', -1],\n",
       "       [0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        '51320_2015', -1]], dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_path[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "565d79a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] The path was created for each item in the dataframe, by looking at its history, so to include embeddings in the FFN input, we concatenate the embeddings for each sentence / text.\n"
     ]
    }
   ],
   "source": [
    "x_data, input_channels = manifesto_data.get_torch_path_for_SDSN(\n",
    "    include_time_features_in_path = True,\n",
    "    include_time_features_in_input = True,\n",
    "    include_embedding_in_input = True,\n",
    "    reduced_embeddings=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bcf59878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15610, 10, 822])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "51b5cf59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "822"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_channels+len(time_features)+768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01826eec",
   "metadata": {},
   "source": [
    "## StackedDeepSigNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "70814c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2022\n",
    "SDSN_args = {\n",
    "    \"input_channels\": input_channels,\n",
    "    \"output_channels\": 10,\n",
    "    \"num_time_features\": len(time_features),\n",
    "    \"embedding_dim\": x_data.shape[2]-input_channels-len(time_features),\n",
    "    \"sig_depth\": 3,\n",
    "    \"hidden_dim_lstm\": (12, 8),\n",
    "    \"hidden_dim\": 32,\n",
    "    \"output_dim\": len(manifesto_data.df[\"switched_topic\"].unique()),\n",
    "    \"dropout_rate\": 0.25,\n",
    "    \"augmentation_type\": \"Conv1d\",\n",
    "    \"augmentation_layers\": (),\n",
    "    \"blocks\": 2,\n",
    "    \"BiLSTM\": False,\n",
    "    \"comb_method\": \"concatenation\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "07d89006",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folds = nlpsig.Folds(x_data=x_data,\n",
    "                          y_data=torch.tensor(manifesto_data.df[\"switched_topic\"]),\n",
    "                          n_splits=2,\n",
    "                          shuffle=True,\n",
    "                          random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f769909f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid, test = data_folds.get_splits(fold_index = 1,\n",
    "                                           as_DataLoader = True,\n",
    "                                           data_loader_args = {\"batch_size\": 512,\n",
    "                                                               \"shuffle\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ea3e18e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial model definitions\n",
    "model = StackedDeepSigNet(**SDSN_args)\n",
    "\n",
    "# define loss\n",
    "loss = \"cross_entropy\"\n",
    "num_folds = 5\n",
    "gamma = 2\n",
    "beta = 0.999\n",
    "\n",
    "if loss == \"focal\":    \n",
    "    criterion = FocalLoss(gamma = gamma)\n",
    "    y_train = data_folds.get_splits(fold_index=0)[5]\n",
    "    criterion.set_alpha_from_y(y=y_train)\n",
    "elif loss == \"cbfocal\":\n",
    "    criterion = ClassBalanced_FocalLoss(gamma = gamma,\n",
    "                                        beta = beta,\n",
    "                                        no_of_classes = 2)\n",
    "    y_train = data_folds.get_splits(fold_index=0)[5]\n",
    "    criterion.set_samples_per_cls_from_y(y=y_train)\n",
    "elif loss == \"cross_entropy\":\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "# define optimizer\n",
    "learning_rate = 0.00005\n",
    "weight_decay_adam = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c6255c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "labels_all = torch.empty((0))\n",
    "predicted_all = torch.empty((0))\n",
    "with torch.no_grad():\n",
    "    # Iterate through test dataset\n",
    "    for emb_t, labels_t in test:\n",
    "        # make prediction\n",
    "        outputs_t = model(emb_t)\n",
    "        \n",
    "        _, predicted_t = torch.max(outputs_t.data, 1)\n",
    "        # save predictions and labels\n",
    "        labels_all = torch.cat([labels_all, labels_t])\n",
    "        predicted_all = torch.cat([predicted_all, predicted_t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "24e842fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([-1.2756e+00,  2.4272e+00, -3.2802e+00,  2.1688e+00,  2.4247e+00,\n",
       "        -3.4462e+00,  1.4838e+00, -8.6385e-01,  2.4163e+00, -3.3502e+00,\n",
       "         2.3720e+00,  2.4298e+00,  1.7554e+00,  2.8861e-01,  2.4336e+00,\n",
       "         2.3991e+00, -2.0071e+00, -2.6585e+00, -2.4787e+00, -2.1174e-01,\n",
       "         1.9039e+00,  2.4216e+00, -3.9033e+00,  2.3696e+00,  2.3864e+00,\n",
       "         2.1087e+00,  2.4036e+00,  8.0496e-01,  2.3953e+00,  6.7340e-01,\n",
       "        -8.0522e-01,  2.4265e+00,  2.4281e+00,  1.6523e-01,  2.4231e+00,\n",
       "         2.4048e+00,  1.9673e+00,  2.3854e+00,  2.3859e+00,  2.4259e+00,\n",
       "         2.1200e+00, -5.5159e-01, -3.8687e-01,  2.3187e-01, -3.5015e+00,\n",
       "         2.7930e-01,  2.3806e+00,  6.7263e-01,  2.3914e+00, -6.8284e-01,\n",
       "         2.1221e+00,  5.5558e-01, -4.6560e-01, -2.4544e+00,  2.3911e+00,\n",
       "         2.4070e+00, -2.2983e+00,  2.0891e+00,  2.4128e+00,  1.4829e+00,\n",
       "         2.3805e+00, -4.2980e-01, -3.3113e+00,  2.4217e+00, -1.3584e+00,\n",
       "         2.4201e+00,  2.3949e+00,  1.6318e+00, -2.5681e+00,  2.4188e+00,\n",
       "         2.4204e+00,  2.0220e+00,  2.7194e-03, -4.0493e+00, -1.2307e+00,\n",
       "         5.1941e-01, -3.5290e+00,  1.3055e+00, -1.5613e-01,  1.5214e+00,\n",
       "         2.3918e+00,  2.4115e+00,  2.3725e+00, -2.4719e+00, -1.5153e-01,\n",
       "         2.4169e+00, -5.8733e-01,  2.1303e-01, -9.0591e-01,  4.1436e-01,\n",
       "         1.2155e+00, -3.4333e+00, -2.9759e+00,  1.9396e+00, -1.9124e+00,\n",
       "         2.4179e+00,  2.4482e-01,  1.9887e+00,  2.3785e+00,  4.3740e-02,\n",
       "        -8.0142e-01,  1.2668e+00, -1.1748e+00,  2.4135e+00,  7.1251e-01,\n",
       "         2.4218e+00,  2.4221e+00,  8.4304e-02,  6.4174e-01, -4.4030e-01,\n",
       "        -1.0280e+00,  9.6819e-01,  2.4189e+00,  1.7049e+00,  2.2349e+00,\n",
       "         2.1307e+00,  1.5640e+00,  1.2223e+00,  1.3485e+00,  2.4122e+00,\n",
       "        -4.0069e+00,  2.3789e+00, -4.6525e+00, -3.4740e+00, -3.2536e+00]),\n",
       "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(outputs_t, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3655baa2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                              | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000 || Item: 0/11 || Loss: 2.8005354404449463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                      | 1/1000 [00:01<17:30,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "##### Epoch: 1/1000 || Loss: 2.5524680614471436\n",
      "--------------------------------------------------\n",
      "Epoch: 1 || Loss: 2.4225887854894004 || Accuracy: 0.6948757767677307 || F1-score: 0.40998625744388456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|██                                                                                                   | 20/1000 [00:20<16:25,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/1000 || Item: 0/11 || Loss: 0.6099115014076233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██                                                                                                   | 21/1000 [00:21<16:22,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "##### Epoch: 21/1000 || Loss: 0.6370500326156616\n",
      "--------------------------------------------------\n",
      "Epoch: 21 || Loss: 0.6043670276800791 || Accuracy: 0.6948757767677307 || F1-score: 0.40998625744388456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|████                                                                                                 | 40/1000 [00:40<16:08,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/1000 || Item: 0/11 || Loss: 0.6057258248329163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|████▏                                                                                                | 41/1000 [00:41<16:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "##### Epoch: 41/1000 || Loss: 0.639003574848175\n",
      "--------------------------------------------------\n",
      "Epoch: 41 || Loss: 0.6047622760136923 || Accuracy: 0.6948757767677307 || F1-score: 0.40998625744388456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████                                                                                               | 60/1000 [01:00<15:46,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/1000 || Item: 0/11 || Loss: 0.5969003438949585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|██████▏                                                                                              | 61/1000 [01:01<15:43,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "##### Epoch: 61/1000 || Loss: 0.5788325071334839\n",
      "--------------------------------------------------\n",
      "Epoch: 61 || Loss: 0.5883557001749674 || Accuracy: 0.6948757767677307 || F1-score: 0.40998625744388456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|████████                                                                                             | 80/1000 [01:21<15:49,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/1000 || Item: 0/11 || Loss: 0.6002448201179504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|████████▏                                                                                            | 81/1000 [01:22<15:49,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "##### Epoch: 81/1000 || Loss: 0.567249059677124\n",
      "--------------------------------------------------\n",
      "Epoch: 81 || Loss: 0.5905295809110006 || Accuracy: 0.6948757767677307 || F1-score: 0.40998625744388456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|██████████                                                                                          | 100/1000 [01:42<15:19,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101/1000 || Item: 0/11 || Loss: 0.6132428646087646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██████████                                                                                          | 101/1000 [01:43<15:22,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "##### Epoch: 101/1000 || Loss: 0.5665322542190552\n",
      "--------------------------------------------------\n",
      "Epoch: 101 || Loss: 0.5983361899852753 || Accuracy: 0.6948757767677307 || F1-score: 0.40998625744388456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████████                                                                                        | 120/1000 [02:02<14:53,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121/1000 || Item: 0/11 || Loss: 0.6197059750556946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|████████████                                                                                        | 121/1000 [02:03<14:56,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "##### Epoch: 121/1000 || Loss: 0.6034596562385559\n",
      "--------------------------------------------------\n",
      "Epoch: 121 || Loss: 0.5835073590278625 || Accuracy: 0.6948757767677307 || F1-score: 0.40998625744388456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████████████                                                                                      | 140/1000 [02:23<14:44,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 141/1000 || Item: 0/11 || Loss: 0.612939715385437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████████████                                                                                      | 141/1000 [02:24<14:39,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "##### Epoch: 141/1000 || Loss: 0.5837703943252563\n",
      "--------------------------------------------------\n",
      "Epoch: 141 || Loss: 0.599367082118988 || Accuracy: 0.6948757767677307 || F1-score: 0.40998625744388456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|████████████████                                                                                    | 160/1000 [02:43<14:22,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 161/1000 || Item: 0/11 || Loss: 0.6173762679100037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████████                                                                                    | 161/1000 [02:44<14:17,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "##### Epoch: 161/1000 || Loss: 0.6611766815185547\n",
      "--------------------------------------------------\n",
      "Epoch: 161 || Loss: 0.6174136400222778 || Accuracy: 0.6948757767677307 || F1-score: 0.40998625744388456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|██████████████████                                                                                  | 180/1000 [03:04<14:10,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 181/1000 || Item: 0/11 || Loss: 0.6334825754165649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████████                                                                                  | 181/1000 [03:05<14:41,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "##### Epoch: 181/1000 || Loss: 0.6217061281204224\n",
      "--------------------------------------------------\n",
      "Epoch: 181 || Loss: 0.5959498186906179 || Accuracy: 0.6948757767677307 || F1-score: 0.40998625744388456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|███████████████████▎                                                                                | 193/1000 [03:19<13:52,  1.03s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [125], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mnlpsig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_pytorch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mverbose_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/rough_paths/path_signatures_bert/nlpsig/pytorch_utils.py:142\u001b[0m, in \u001b[0;36mtraining_pytorch\u001b[0;34m(model, train_loader, valid_loader, criterion, optimizer, num_epochs, seed, patience, verbose, verbose_epoch, verbose_item)\u001b[0m\n\u001b[1;32m    140\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(emb)\n\u001b[1;32m    141\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m--> 142\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# show training progress\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py38esig/lib/python3.8/site-packages/torch/_tensor.py:255\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    248\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    249\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    254\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 255\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py38esig/lib/python3.8/site-packages/torch/autograd/__init__.py:147\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m--> 147\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py38esig/lib/python3.8/site-packages/torch/autograd/function.py:87\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py38esig/lib/python3.8/site-packages/torch/autograd/function.py:204\u001b[0m, in \u001b[0;36monce_differentiable.<locals>.wrapper\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(ctx, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 204\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled():\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py38esig/lib/python3.8/site-packages/signatory/signature_module.py:83\u001b[0m, in \u001b[0;36m_SignatureFunction.backward\u001b[0;34m(ctx, grad_result)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# PyTorch 1.5 changed how clone etc. work wrt memory format; this can then throw an error unless we do this.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Ideally we'd go through all the code and make every memory-format-aware op actually create contiguous rather\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# than format-preserved tensors, but that's a lot more work and won't compile with pre-1.5, when the concept\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# didn't exist.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m path_increments \u001b[38;5;241m=\u001b[39m path_increments\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m---> 83\u001b[0m grad_path, grad_basepoint, grad_initial \u001b[38;5;241m=\u001b[39m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath_increments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasepoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_term\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mbasepoint_is_tensor:\n\u001b[1;32m     88\u001b[0m     grad_basepoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/py38esig/lib/python3.8/site-packages/signatory/impl.py:36\u001b[0m, in \u001b[0;36m_wrap.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trained_model = nlpsig.training_pytorch(model = model,\n",
    "                                        train_loader = train,\n",
    "                                        valid_loader = valid,\n",
    "                                        criterion = criterion,\n",
    "                                        optimizer = optimizer,\n",
    "                                        num_epochs = 1000,\n",
    "                                        seed = seed,\n",
    "                                        patience = 10,\n",
    "                                        verbose = True,\n",
    "                                        verbose_epoch = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8fef0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653cdcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b63ffede",
   "metadata": {},
   "source": [
    "Baselines:\n",
    "   - just looking at the sentence embeddings (encodes nothing about the history on the post)\n",
    "       - highlights importance of looking at the sequence\n",
    "   - averaging history\n",
    "   - comparing the cosine similarity between previous post and current post to see if switch\n",
    "   \n",
    "Test for:\n",
    "- How many posts do you need to look back?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fc762723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51421_2015    1917\n",
       "51320_2019    1702\n",
       "51620_2015    1588\n",
       "51620_2017    1496\n",
       "51421_2019    1467\n",
       "51320_2017    1328\n",
       "51620_2019    1223\n",
       "51421_2017    1131\n",
       "51902_2019    1071\n",
       "51320_2015    1009\n",
       "51902_2015     892\n",
       "51902_2017     786\n",
       "Name: doc_id, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_data.df[\"doc_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d2f06c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeline_index</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>d9</th>\n",
       "      <th>d10</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>switched_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51320_2015</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.452659</td>\n",
       "      <td>3.602911</td>\n",
       "      <td>8.050925</td>\n",
       "      <td>10.075459</td>\n",
       "      <td>3.911385</td>\n",
       "      <td>9.213820</td>\n",
       "      <td>5.951643</td>\n",
       "      <td>4.275470</td>\n",
       "      <td>1.188564</td>\n",
       "      <td>2.751409</td>\n",
       "      <td>51320_2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.111912</td>\n",
       "      <td>3.501168</td>\n",
       "      <td>7.925458</td>\n",
       "      <td>10.427611</td>\n",
       "      <td>3.838215</td>\n",
       "      <td>9.157601</td>\n",
       "      <td>6.385989</td>\n",
       "      <td>4.594971</td>\n",
       "      <td>1.200033</td>\n",
       "      <td>3.107747</td>\n",
       "      <td>51320_2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.043742</td>\n",
       "      <td>3.522960</td>\n",
       "      <td>7.468404</td>\n",
       "      <td>9.604556</td>\n",
       "      <td>3.859646</td>\n",
       "      <td>9.537117</td>\n",
       "      <td>6.133909</td>\n",
       "      <td>4.508759</td>\n",
       "      <td>0.930652</td>\n",
       "      <td>2.949600</td>\n",
       "      <td>51320_2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5.246913</td>\n",
       "      <td>3.351569</td>\n",
       "      <td>7.850750</td>\n",
       "      <td>8.427454</td>\n",
       "      <td>4.078413</td>\n",
       "      <td>9.972346</td>\n",
       "      <td>6.232757</td>\n",
       "      <td>4.770494</td>\n",
       "      <td>1.519472</td>\n",
       "      <td>2.442487</td>\n",
       "      <td>51320_2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>4.939366</td>\n",
       "      <td>2.744935</td>\n",
       "      <td>6.556887</td>\n",
       "      <td>9.778514</td>\n",
       "      <td>5.032885</td>\n",
       "      <td>9.680021</td>\n",
       "      <td>8.184111</td>\n",
       "      <td>4.553108</td>\n",
       "      <td>1.828841</td>\n",
       "      <td>2.317884</td>\n",
       "      <td>51320_2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1005</td>\n",
       "      <td>3.629394</td>\n",
       "      <td>2.353125</td>\n",
       "      <td>7.404681</td>\n",
       "      <td>10.038898</td>\n",
       "      <td>5.321763</td>\n",
       "      <td>9.898950</td>\n",
       "      <td>7.223835</td>\n",
       "      <td>4.316514</td>\n",
       "      <td>2.549977</td>\n",
       "      <td>2.290533</td>\n",
       "      <td>51320_2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1006</td>\n",
       "      <td>4.761509</td>\n",
       "      <td>3.163177</td>\n",
       "      <td>7.822935</td>\n",
       "      <td>10.507176</td>\n",
       "      <td>4.688953</td>\n",
       "      <td>8.588090</td>\n",
       "      <td>8.575832</td>\n",
       "      <td>4.712253</td>\n",
       "      <td>1.761940</td>\n",
       "      <td>2.563453</td>\n",
       "      <td>51320_2015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1007</td>\n",
       "      <td>4.707180</td>\n",
       "      <td>3.207190</td>\n",
       "      <td>7.543126</td>\n",
       "      <td>10.101868</td>\n",
       "      <td>4.077579</td>\n",
       "      <td>9.360678</td>\n",
       "      <td>6.383281</td>\n",
       "      <td>4.666095</td>\n",
       "      <td>1.278698</td>\n",
       "      <td>3.281799</td>\n",
       "      <td>51320_2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1008</td>\n",
       "      <td>3.752553</td>\n",
       "      <td>2.973253</td>\n",
       "      <td>7.434272</td>\n",
       "      <td>10.667103</td>\n",
       "      <td>4.141184</td>\n",
       "      <td>9.334723</td>\n",
       "      <td>8.390216</td>\n",
       "      <td>4.703103</td>\n",
       "      <td>1.720346</td>\n",
       "      <td>3.037463</td>\n",
       "      <td>51320_2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timeline_index        d1        d2        d3         d4        d5  \\\n",
       "0                  0  0.000000  0.000000  0.000000   0.000000  0.000000   \n",
       "1                  1  5.452659  3.602911  8.050925  10.075459  3.911385   \n",
       "2                  2  5.111912  3.501168  7.925458  10.427611  3.838215   \n",
       "3                  3  5.043742  3.522960  7.468404   9.604556  3.859646   \n",
       "4                  4  5.246913  3.351569  7.850750   8.427454  4.078413   \n",
       "...              ...       ...       ...       ...        ...       ...   \n",
       "1004            1004  4.939366  2.744935  6.556887   9.778514  5.032885   \n",
       "1005            1005  3.629394  2.353125  7.404681  10.038898  5.321763   \n",
       "1006            1006  4.761509  3.163177  7.822935  10.507176  4.688953   \n",
       "1007            1007  4.707180  3.207190  7.543126  10.101868  4.077579   \n",
       "1008            1008  3.752553  2.973253  7.434272  10.667103  4.141184   \n",
       "\n",
       "            d6        d7        d8        d9       d10      doc_id  \\\n",
       "0     0.000000  0.000000  0.000000  0.000000  0.000000  51320_2015   \n",
       "1     9.213820  5.951643  4.275470  1.188564  2.751409  51320_2015   \n",
       "2     9.157601  6.385989  4.594971  1.200033  3.107747  51320_2015   \n",
       "3     9.537117  6.133909  4.508759  0.930652  2.949600  51320_2015   \n",
       "4     9.972346  6.232757  4.770494  1.519472  2.442487  51320_2015   \n",
       "...        ...       ...       ...       ...       ...         ...   \n",
       "1004  9.680021  8.184111  4.553108  1.828841  2.317884  51320_2015   \n",
       "1005  9.898950  7.223835  4.316514  2.549977  2.290533  51320_2015   \n",
       "1006  8.588090  8.575832  4.712253  1.761940  2.563453  51320_2015   \n",
       "1007  9.360678  6.383281  4.666095  1.278698  3.281799  51320_2015   \n",
       "1008  9.334723  8.390216  4.703103  1.720346  3.037463  51320_2015   \n",
       "\n",
       "      switched_topic  \n",
       "0                 -1  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "1004               1  \n",
       "1005               1  \n",
       "1006               1  \n",
       "1007               0  \n",
       "1008               0  \n",
       "\n",
       "[1009 rows x 13 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_data.df_padded[manifesto_data.df_padded[\"doc_id\"]==\"51320_2015\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "10ab4d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15610, 1, 10])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifesto_data.get_torch_path(include_time_features=False).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf908bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        '51320_2015', -1],\n",
       "       [0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "        '51320_2015', -1],\n",
       "       [1, 5.452658653259277, 3.6029112339019775, 8.050925254821777,\n",
       "        10.075458526611328, 3.9113845825195312, 9.213820457458496,\n",
       "        5.951642990112305, 4.27547025680542, 1.1885640621185303,\n",
       "        2.751408576965332, '51320_2015', 1],\n",
       "       [2, 5.111911773681641, 3.5011675357818604, 7.9254584312438965,\n",
       "        10.427611351013184, 3.838214874267578, 9.157601356506348,\n",
       "        6.385989189147949, 4.594970703125, 1.2000325918197632,\n",
       "        3.1077473163604736, '51320_2015', 0],\n",
       "       [3, 5.043741703033447, 3.5229599475860596, 7.4684038162231445,\n",
       "        9.6045560836792, 3.8596458435058594, 9.537117004394531,\n",
       "        6.133909225463867, 4.508759498596191, 0.9306520223617554,\n",
       "        2.9496004581451416, '51320_2015', 0]], dtype=object)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_path[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7116cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_tp = model_specifics[\"augmentation_tp\"]\n",
    "input_channels = path.shape[2]\n",
    "output_channels =  [model_specifics[\"reduced_network_components\"]] #13#[10,13]\n",
    "augmentation_layers = () #[(32, 16, 10)] #(50, 20, output_channels) #\n",
    "BiLSTM = False\n",
    "sig_d = 3 \n",
    "blocks = 3\n",
    "post_dim = x_data.shape[1]- input_channels\n",
    "hidden_dim_lstm =  [(12, 8)] #12 [10,12]\n",
    "hidden_dim = [32] #32 [32,64] \n",
    "output_dim = 3\n",
    "loss = model_specifics[\"loss_function\"] #'focal' #cbfocal\n",
    "dropout_rate = [0.25]  #0.25 [0.25,0.35]\n",
    "if (model_specifics['time_injection_history_tp'] == 'timestamp'):\n",
    "    add_time = True\n",
    "else: \n",
    "    add_time = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29784de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lass DeepSigNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels,\n",
    "        output_channels,\n",
    "        sig_d,\n",
    "        post_dim,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        dropout_rate,\n",
    "        add_time=False,\n",
    "        augmentation_tp=\"Conv1d\",\n",
    "        augmentation_layers=(),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py38esig)",
   "language": "python",
   "name": "py38esig"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
