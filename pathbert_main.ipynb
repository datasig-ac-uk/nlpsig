{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT and Path signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve issue with autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(0, \"../../timeline_generation/\")  # Adds higher directory to python modules path\n",
    "# import src.data_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"newspop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df_all = pd.DataFrame(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [\"headline\", \"publish_date\", \"topic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset_df_all[use_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randrange, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_datetimes = [\"2015-01-01 00:00:00\",\n",
    "                  \"2015-01-01 00:12:00\",\n",
    "                  \"2015-01-02 00:00:00\",\n",
    "                  \"2015-01-02 00:12:00\",\n",
    "                  \"2015-01-03 00:00:00\",\n",
    "                  \"2015-01-03 00:12:00\",\n",
    "                  \"2015-01-04 00:00:00\",\n",
    "                  \"2015-01-04 00:12:00\",\n",
    "                  \"2015-01-05 00:00:00\",\n",
    "                  \"2015-01-05 00:12:00\",\n",
    "                  \"2015-01-06 00:00:00\",\n",
    "                  \"2015-01-06 00:12:00\"\n",
    "                 ]\n",
    "dataset_df[\"publish_date\"] = [choice(list_datetimes) for x in range(len(dataset_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[\"timeline_id\"] = dataset_df[\"publish_date\"].apply(lambda x: list_datetimes.index(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[\"postid\"] = [randrange(10) for x in range(len(dataset_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols = {\n",
    "    \"headline\": \"content\",\n",
    "    \"publish_date\": \"datetime\",\n",
    "    \"topic\": \"label\",\n",
    "    \"timeline_id\": \"timeline_id\",\n",
    "    \"postid\": \"postid\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset_df.rename(columns=rename_cols)\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['datetime'] =  pd.to_datetime(dataset_df['datetime'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_labels = {\n",
    "    \"label\": \n",
    "        {\"economy\": 2,\n",
    "         \"obama\": 1,\n",
    "         \"microsoft\": 0,\n",
    "         \"palestine\": 0\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset_df.replace(encode_labels)\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = dataset_df[:500]\n",
    "dataset_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "#model specifics\n",
    "model_specifics = {\"global_embedding_tp\": 'SBERT', #options: SBERT, BERT_cls , BERT_mean, BERT_max\n",
    "    \"dimensionality_reduction_tp\": 'ppapca', #options: ppapca, ppapcappa, umap\n",
    "    \"dimensionality_reduction_components\": 10, # options: any int number between 1 and embedding dimensions\n",
    "    \"time_injection_history_tp\": 'timestamp', #options: timestamp, None\n",
    "    \"time_injection_post_tp\": 'timestamp', #options: timestamp, timediff, None\n",
    "    \"signature_dimensions\": 3, #options: any int number larger than 1\n",
    "    \"post_embedding_tp\": 'sentence', #options: sentence, reduced\n",
    "    \"feature_combination_method\": 'attention', #options concatenation, attention \n",
    "    \"signature_tp\": 'log', # options: log, sig\n",
    "    \"classifier_name\": 'FFN2hidden', # options: FFN2hidden (any future classifiers added)\n",
    "    \"classes_num\": '3class', #options: 3class (5class to be added in the future)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sentences = dataset_df[\"content\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_sentence = st_model.encode(sentences,\n",
    "                                      batch_size=64,\n",
    "                                      show_progress_bar=True,\n",
    "                                      output_value='sentence_embedding', \n",
    "                                      convert_to_numpy=True,\n",
    "                                      convert_to_tensor=False,\n",
    "                                      device=None,\n",
    "                                      normalize_embeddings=False,\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensionality reduction\n",
    "from src import DimensionalityReduction\n",
    "\n",
    "reduction = DimensionalityReduction(method= model_specifics['dimensionality_reduction_tp'], \n",
    "                                    components=model_specifics['dimensionality_reduction_components'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_reduced = reduction.fit_transform(embeddings_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings_sentence.shape)\n",
    "print(embeddings_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#concatenate new dataframe\n",
    "from src.dataset import get_modeling_dataframe\n",
    "df = get_modeling_dataframe(dataset_df, embeddings_sentence, embeddings_reduced)\n",
    "\n",
    "#get time features\n",
    "from src.timeinjection import TimeFeatures, Padding\n",
    "tf = TimeFeatures()\n",
    "df = tf.get_time_features(df)\n",
    "\n",
    "\n",
    "#padding\n",
    "pad = Padding()\n",
    "df_padded = pad.pad_timelines(df)\n",
    "df_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (model_specifics['time_injection_history_tp'] == 'timestamp'):\n",
    "    path = torch.from_numpy(df_padded[: , : , 2:].astype(float))\n",
    "else:\n",
    "    path = torch.from_numpy(df_padded[: , : , 3:].astype(float))\n",
    "\n",
    "if (model_specifics['time_injection_post_tp']== 'timestamp'):\n",
    "    time_feature = torch.tensor((df[['time_encoding']].values - df['time_encoding'].mean()) / df['time_encoding'].std() )\n",
    "    post_time = True\n",
    "elif (model_specifics['time_injection_post_tp']== 'timediff'):\n",
    "    time_feature = torch.tensor( (df[['time_diff']].values - df['time_diff'].mean()) / df['time_diff'].std()  )\n",
    "    post_time = True  \n",
    "else: \n",
    "    time_feature = None\n",
    "    post_time = False\n",
    "\n",
    "if (model_specifics['post_embedding_tp'] == 'sentence'):\n",
    "    bert_embeddings = torch.tensor(df[[c for c in df.columns if re.match(\"^e\\w*[0-9]\", c)]].values)\n",
    "else:\n",
    "    bert_embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = path.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate paths\n",
    "from src.dyadic_path import DyadicSignatures\n",
    "\n",
    "dsig = DyadicSignatures(original_size = df.shape[0], \n",
    "                        d = path.shape[2], \n",
    "                        sig_d = model_specifics['signature_dimensions'],\n",
    "                        intervals = 1/12, \n",
    "                        k_history= None, \n",
    "                        embedding_tp = model_specifics['post_embedding_tp'],\n",
    "                        method = model_specifics['feature_combination_method'],\n",
    "                        history_tp = model_specifics['signature_tp'], \n",
    "                        add_time = post_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig, last_index_dt_all = dsig.compute_signatures(path)\n",
    "sig_combined = dsig.combine_signatures(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = dsig.create_features(path, sig_combined, last_index_dt_all, bert_embeddings, time_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.shape, last_index_dt_all.shape, sig_combined.shape, x_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc2069cb215c7de2e5937e427ca306059c4ba817c7096ba614207074d673f065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
