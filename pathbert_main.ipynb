{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features from textual data using BERT and Path signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solve issue with autocomplete\n",
    "%config Completer.use_jedi = False\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "# import sys\n",
    "# sys.path.insert(0, \"../../timeline_generation/\")  # Adds higher directory to python modules path\n",
    "# import src.data_handler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadHF: load a dataset from hugging face\n",
    "from src import loadHF\n",
    "data_loader = loadHF(dataset_name=\"newspop\", \n",
    "                     split_name=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: default_preproces_newspop is implemented in loadHF\n",
    "data_loader.load_preprocessed_df(default_preprocess=\"newspop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = data_loader.dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST: use a slice of dataset_df\n",
    "\n",
    "dataset_df = dataset_df[:1500]\n",
    "dataset_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model specifics\n",
    "\n",
    "Nested dictionary for models specifications.\n",
    "\n",
    "This includes models for encoding text, path signature and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_specifics = {\n",
    "    \"encoder_args\": {\n",
    "        \"col_name_text\": \"content\",\n",
    "        \"model_name\": \"all-MiniLM-L6-v2\",\n",
    "        \"model_args\": {\n",
    "            \"batch_size\": 64,\n",
    "            \"show_progress_bar\": True,\n",
    "            \"output_value\": 'sentence_embedding', \n",
    "            \"convert_to_numpy\": True,\n",
    "            \"convert_to_tensor\": False,\n",
    "            \"device\": None,\n",
    "            \"normalize_embeddings\": False\n",
    "        }\n",
    "    },\n",
    "    \"dim_reduction\": {\n",
    "        \"method\": 'ppapca', #options: ppapca, ppapcappa, umap\n",
    "        \"num_components\": 10, # options: any int number between 1 and embedding dimensions\n",
    "    },\n",
    "    \"time_injection\": {\n",
    "        \"history_tp\": 'timestamp', #options: timestamp, None\n",
    "        \"post_tp\": 'timestamp', #options: timestamp, timediff, None\n",
    "    },\n",
    "    \"embedding\":{\n",
    "        \"global_embedding_tp\": 'SBERT', #options: SBERT, BERT_cls , BERT_mean, BERT_max\n",
    "        \"post_embedding_tp\": 'sentence', #options: sentence, reduced\n",
    "        \"feature_combination_method\": 'attention', #options concatenation, attention \n",
    "    },\n",
    "    \"signature\": {\n",
    "        \"dimensions\": 3, #options: any int number larger than 1\n",
    "        \"method\": 'log', # options: log, sig\n",
    "        \"interval\": 1/12\n",
    "    },\n",
    "    \"classifier\": {\n",
    "        \"classifier_name\": 'FFN2hidden', # options: FFN2hidden (any future classifiers added)\n",
    "        \"classes_num\": '3class', #options: 3class (5class to be added in the future)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode text and reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import textEncoder\n",
    "text_encoder = textEncoder(dataset_df,\n",
    "                           col_name_text=model_specifics[\"encoder_args\"][\"col_name_text\"], \n",
    "                           model_name=model_specifics[\"encoder_args\"][\"model_name\"],\n",
    "                           model_args=model_specifics[\"encoder_args\"][\"model_args\"]\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder.encode_sentence_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_sentence = text_encoder.embeddings_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import plotEmbedding\n",
    "\n",
    "plt_embed = plotEmbedding(x_data=embeddings_sentence,\n",
    "                          y_data=df[\"label\"].values)\n",
    "\n",
    "plt_embed.plt_2d(\n",
    "    embed_args={\"method\": \"umap\",\n",
    "                \"dim\": 3\n",
    "               },\n",
    "    line_args={\"alpha\": 0.1,\n",
    "               \"marker\": \"o\"\n",
    "              }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimensionality reduction\n",
    "from src import DimensionalityReduction\n",
    "\n",
    "reduction = DimensionalityReduction(method= model_specifics[\"dim_reduction\"]['method'], \n",
    "                                    components=model_specifics[\"dim_reduction\"]['num_components'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_reduced = reduction.fit_transform(embeddings_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings_sentence.shape)\n",
    "print(embeddings_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import plotEmbedding\n",
    "\n",
    "plt_embed = plotEmbedding(x_data=embeddings_reduced,\n",
    "                          y_data=df[\"label\"].values)\n",
    "\n",
    "plt_embed.plt_2d(\n",
    "    embed_args={\"method\": \"umap\",\n",
    "                \"dim\": 3\n",
    "               },\n",
    "    line_args={\"alpha\": 0.1,\n",
    "               \"marker\": \"o\"\n",
    "              }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#concatenate new dataframe\n",
    "from src.dataset import get_modeling_dataframe\n",
    "df = get_modeling_dataframe(dataset_df, embeddings_sentence, embeddings_reduced)\n",
    "\n",
    "#get time features\n",
    "from src.timeinjection import TimeFeatures, Padding\n",
    "tf = TimeFeatures()\n",
    "df = tf.get_time_features(df)\n",
    "\n",
    "\n",
    "#padding\n",
    "pad = Padding()\n",
    "df_padded = pad.pad_timelines(df)\n",
    "df_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (model_specifics[\"time_injection\"][\"history_tp\"] == 'timestamp'):\n",
    "    path = torch.from_numpy(df_padded[: , : , 2:].astype(float))\n",
    "else:\n",
    "    path = torch.from_numpy(df_padded[: , : , 3:].astype(float))\n",
    "\n",
    "if (model_specifics[\"time_injection\"][\"post_tp\"]== 'timestamp'):\n",
    "    time_feature = torch.tensor((df[['time_encoding']].values - df['time_encoding'].mean()) / df['time_encoding'].std() )\n",
    "    post_time = True\n",
    "elif (model_specifics[\"time_injection\"][\"post_tp\"]== 'timediff'):\n",
    "    time_feature = torch.tensor( (df[['time_diff']].values - df['time_diff'].mean()) / df['time_diff'].std()  )\n",
    "    post_time = True  \n",
    "else: \n",
    "    time_feature = None\n",
    "    post_time = False\n",
    "\n",
    "if (model_specifics[\"embedding\"]['post_embedding_tp'] == 'sentence'):\n",
    "    bert_embeddings = torch.tensor(df[[c for c in df.columns if re.match(\"^e\\w*[0-9]\", c)]].values)\n",
    "else:\n",
    "    bert_embeddings = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = path.squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute signature and create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate paths\n",
    "from src.dyadic_path import DyadicSignatures\n",
    "\n",
    "dsig = DyadicSignatures(original_size = df.shape[0], \n",
    "                        d = path.shape[2], \n",
    "                        sig_d = model_specifics[\"signature\"]['dimensions'],\n",
    "                        intervals = model_specifics[\"signature\"][\"interval\"], \n",
    "                        k_history= None, \n",
    "                        embedding_tp = model_specifics[\"embedding\"]['post_embedding_tp'],\n",
    "                        method = model_specifics[\"embedding\"]['feature_combination_method'],\n",
    "                        history_tp = model_specifics[\"signature\"]['method'], \n",
    "                        add_time = post_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig, last_index_dt_all = dsig.compute_signatures(path)\n",
    "sig_combined = dsig.combine_signatures(sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = dsig.create_features(path, sig_combined, last_index_dt_all, bert_embeddings, time_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.shape, last_index_dt_all.shape, sig_combined.shape, x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import plotEmbedding\n",
    "\n",
    "plt_embed = plotEmbedding(x_data=x_data,\n",
    "                          y_data=df[\"label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_embed.plt_2d(\n",
    "    embed_args={\"method\": \"pca\",\n",
    "                \"dim\": 3\n",
    "               },\n",
    "    line_args={\"alpha\": 0.1,\n",
    "               \"marker\": \"o\"\n",
    "              }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_embed.plt_2d(\n",
    "    embed_args={\"method\": \"umap\",\n",
    "                \"dim\": 3\n",
    "               },\n",
    "    line_args={\"alpha\": 0.01,\n",
    "               \"marker\": \"o\"\n",
    "              }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing: Training classifiers, cross validation, ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bc2069cb215c7de2e5937e427ca306059c4ba817c7096ba614207074d673f065"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
